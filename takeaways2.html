<!DOCTYPE html>
<html lang="en">

<head>
<meta charset="utf-8" />
<link rel="stylesheet" href="https://dokie.li/media/css/lncs.css" />
<title>Takeaways for Week 2</title>
</head>

<body>

<h1>Takeaways for Week 2</h1>

<h2>Topics</h2>

<h3>Resource Descriptions</h3>

<p class="counter">
There are many resources on the Web, and in order to manage, access, and refer to them, they should be described. Nemes are often not enough, because something might have several names. A possible solution is a unique and persistent identifier (e.g. URLs). A resource is classified into one of four classes: Intrinsic static, Extrinsic static, Intrinsic dynamic, Extrinsic dynamic. 
Tagging is also an example of resource description, but it is not principled, and it has many disadvantages, for example a video might have a huge number of tags that do not describe the resource itself. Therefore, classification is a good solution, where classification is purposeful and principled, subjective and biased. In order to use resource descriptions in software systems, logic and ontologies should be used to enable relations and hierarchy.
</p>

<h2>Literature</h2>

<h3>Shoham 2015</h3>

<p class="counter">
A shift has occurred in the way people think of Artificial intelligence between twenty years ago and nowadays  (between the 90th and now). In the 90th, knowledge representation (KR) was the definition known when talking about Artificial intelligence, and the focus was centered on KR. Nowadays, knowledge representation is not receiving the same amount of attention any more, because the shift has occurred where the focus now is on machine learning and its applications. However, Shoham states that KR does still matter, and he gives a number of examples where KR was of great value. One example was the idea of the 
Personal Time Assistant (PTA) that was developed by his company “Timeful”, 
which expresses the role of KR. PTA helps with time management,
and it was built on three main pillars, where one of these pillars was based on KR.  
</p>

<h3>Benson and Karger 2014</h3>

<p class="counter">
It was expected that end users would be capable of tools that allow them to publish their own data, and data visualizations on the web. However, this expectation turned out to be not fully true, but rather, publishing structured data is not very available for novices, and it  requires expertise and access to powerful templating engines. Benson and Karger (2014) conducted their study to assess one possible solution to address this problem, that is called Exhibit, which is a tool that allows users to publish structured and interactive  data visualizations. The results of their study present Exhibit as a tool that is both simple and powerful to meet the needs of the wide range of authors, who need to publish their data in a structured way on the web. 
</p>

<h3>Haas et al. 2011</h3>

<p class="counter">
Haas et al. (2011) propose a new way of displaying Web search results: enhanced search results, where multimedia objects are displayed along with the traditional elements displayed in the traditional Web search results page (title, abstract, author..). These multimedia objects include video, image, and interactive elements  that allow the user to interact with the content of the search results page. The implementation of enhanced search results was done by the use of Information Extraction technologies, and the Semantic Web standards. In order to evaluate the effectiveness of enhanced results, Haas et al. (2011) conducted three experiments, through which they show that users prefer the new way of displaying Web search results (enhanced results) over the traditional one, because it helps them with defining which results are relevant to their search purpose and which results are irrelevant. 
</p>

<h3>Berners-Lee et al. 2001</h3>

<p class="counter">
While the web was introduced originally to be readable to humans, the Semantic web is introduced to be readable for computers as well (machine-readable). This means that documents on the Web will be meaningful not only to humans, but also to software systems. These systems and programs are then able to interact with the web as humans do. The Semantic web was meant to be a place where many kinds of agents will be existing, these agents are responsible for automating many of the tasks that are normally done by humans. Examples of such tasks are making appointments, and looking up addresses. To develop the Semantic Web, two already existing technologies were used, which are (XML) markup language, and the Resource Description Framework (RDF). XML was the technology that allows users to give structure to their document, while RDF was the technology that expresses the meaning in sets of triples (subject, verb, and object). The URI is the technology used to identify the subject, verb, and object. 
</p>

<h2>References</h2>

<ul>
<li>Shoham. 2015. <a href="http://dx.doi.org/10.1145/2803170">Why knowledge representation matters.</a> Communications of the ACM, 59(1).</li>
<li>Benson and Karger. 2014. <a href="http://dx.doi.org/10.1145/2556288.2557036">End-Users Publishing Structured Information on the Web: An Observational Study of What, Why, and How.</a> In CHI 2014.</li>
<li>Haas et al. 2011. <a href="http://dx.doi.org/10.1145/2009916.2010014">Enhanced results for web search.</a> In SIGIR '11.</li>
<li>Berners-Lee, Hendler, and Lassila. 2001. <a href="http://www.scientificamerican.com/article/the-semantic-web/">The Semantic Web.</a> Scientific American, 284(5).</li>
</ul>

<script src="https://raw.githack.com/ucds-vu/ko2021-templates/main/scripts.js"></script>

</body>
</html>

